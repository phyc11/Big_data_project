{
 "cells": [
  {
   "cell_type": "code",


   "execution_count": 4,

   "id": "28c31862-3fa5-43ca-be84-77a438ab43b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang crawl d·ªØ li·ªáu t·ª´ lang-son\n",
      "ƒêang crawl d·ªØ li·ªáu t·ª´ my-tho\n",
      "ƒêang crawl d·ªØ li·ªáu t·ª´ hong-gai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üå§Ô∏è Crawling weather data:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [3:19:42<6:39:25, 11982.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu hong-gai v√†o C:\\Users\\Admin\\Big_data_project\\data_weather\\hong-gai.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üå§Ô∏è Crawling weather data:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [3:19:54<1:22:21, 4941.06s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu lang-son v√†o C:\\Users\\Admin\\Big_data_project\\data_weather\\lang-son.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üå§Ô∏è Crawling weather data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [3:20:46<00:00, 4015.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu my-tho v√†o C:\\Users\\Admin\\Big_data_project\\data_weather\\my-tho.csv\n",
      "\n",
      "‚úÖ ƒê√£ crawl th√†nh c√¥ng: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, WebDriverException\n",
    "\n",
    "def scrape_weather_to_df(name):\n",
    "    # Set up options ƒë·ªÉ gi·∫£m t√†i nguy√™n s·ª≠ d·ª•ng\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--disable-extensions')\n",
    "    options.add_argument('--disable-infobars')\n",
    "    options.add_argument('--disable-notifications')\n",
    "    options.add_argument('--blink-settings=imagesEnabled=false')  # T·∫Øt t·∫£i h√¨nh ·∫£nh\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    url = f\"https://www.worldweatheronline.com/{name}-weather-history/vn.aspx\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    data = []\n",
    "    try:\n",
    "        allow_cookies = WebDriverWait(driver, 15).until(\n",
    "            EC.element_to_be_clickable((By.ID, \"CybotCookiebotDialogBodyButtonAccept\"))\n",
    "        )\n",
    "        allow_cookies.click()\n",
    "        time.sleep(1)\n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        pass\n",
    "    \n",
    "    record_keys = ['Time', 'Weather', 'Temp', 'Rain', 'Cloud', 'Pressure', 'Wind', 'Gust']\n",
    "    date = datetime.datetime(2009, 1, 1)\n",
    "    end_date = datetime.datetime(2025, 4, 18)\n",
    "    \n",
    "    try:\n",
    "        while date < end_date:\n",
    "            date_str = date.strftime('%Y-%m-%d')\n",
    "            try:\n",
    "                input_date = WebDriverWait(driver, 7).until(\n",
    "                    EC.presence_of_element_located((By.ID, 'ctl00_MainContentHolder_txtPastDate'))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].value = arguments[1];\", input_date, date_str)\n",
    "                submit_date = driver.find_element(By.ID, 'ctl00_MainContentHolder_butShowPastWeather')\n",
    "                submit_date.click()\n",
    "            except WebDriverException:\n",
    "                date += datetime.timedelta(days=1)\n",
    "                continue\n",
    "            \n",
    "            time.sleep(1)\n",
    "            \n",
    "            tables = driver.find_element(By.XPATH, \"/html/body/form/div[3]/section/div/div/div/div[3]/div[1]/div/div[3]/table/tbody\")\n",
    "    \n",
    "            all_rows = tables.find_elements(By.TAG_NAME, \"tr\")\n",
    "            rows = all_rows[2:10] \n",
    "            \n",
    "            for row in rows:\n",
    "                try:\n",
    "                    cells = row.find_elements(By.CLASS_NAME, \"days-details-row-item1\")\n",
    "                    rains = row.find_elements(By.CLASS_NAME, \"days-rain-number\")\n",
    "                    rain = rains[0].text\n",
    "                    weather_img = cells[1].find_element(By.TAG_NAME, \"img\")\n",
    "                    weather = weather_img.get_attribute(\"title\")\n",
    "                    \n",
    "                    values = [cells[0].text.strip(), weather, cells[2].text.strip(), rain, cells[3].text.strip(), \n",
    "                            cells[4].text.strip(), cells[5].text.strip(), cells[6].text.strip()]\n",
    "                    \n",
    "                    if values:\n",
    "                        data.append([date_str] + values)\n",
    "                except Exception:\n",
    "                    continue\n",
    "            \n",
    "            date += datetime.timedelta(days=1)\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    \n",
    "    if data:\n",
    "        df = pd.DataFrame(data, columns=[\"Date\"] + record_keys)\n",
    "        return df\n",
    "    else:\n",
    "        return pd.DataFrame(columns=[\"Date\"] + record_keys)\n",
    "\n",
    "def process_location(name, output_dir):\n",
    "    try:\n",
    "        print(f\"ƒêang crawl d·ªØ li·ªáu t·ª´ {name}\")\n",
    "        df = scrape_weather_to_df(name)\n",
    "        filename = os.path.join(output_dir, f\"{name}.csv\")\n",
    "        df.to_csv(filename, index=False)\n",
    "        return f\"‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu {name} v√†o {filename}\", name, True\n",
    "    except Exception as e:\n",
    "        return f\" L·ªói khi crawl {name}: {e}\", name, False\n",
    "\n",
    "def main():\n",
    "    output_dir = r\"C:\\Users\\Admin\\Big_data_project\\data_weather\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",

    "    name_tinh_process = [\"ha-noi\", \"ho-chi-minh-city\", \"da-nang\"] \n",

    "    name_tinh_process = [\"lang-son\", \"my-tho\", \"hong-gai\"]  # Thay b·∫±ng danh s√°ch c·ªßa b·∫°n\n",
>>>>>>> 2cc7e907f3ca92c185089d844d5a33a519c9fcca
    "    \n",
    "   \n",
    "    max_workers = 3  \n",
    "    \n",
    "    results = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # G·ª≠i c√°c t√°c v·ª•\n",
    "        future_to_name = {\n",
    "            executor.submit(process_location, name, output_dir): name \n",
    "            for name in name_tinh_process\n",
    "        }\n",
    "        \n",
    "        # Hi·ªÉn th·ªã ti·∫øn tr√¨nh\n",
    "        with tqdm(total=len(name_tinh_process), desc=\" Crawling weather data\") as pbar:\n",
    "            for future in concurrent.futures.as_completed(future_to_name):\n",
    "                name = future_to_name[future]\n",
    "                try:\n",
    "                    message, location, success = future.result()\n",
    "                    print(message)\n",
    "                    results.append((location, success))\n",
    "                except Exception as e:\n",
    "                    print(f\" L·ªói v·ªõi {name}: {e}\")\n",
    "                    results.append((name, False))\n",
    "                pbar.update(1)\n",
    "    \n",
    "   \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0028f987-acde-468f-99c8-c3f0794d63f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
