{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7634469-d4a4-496f-b5c4-0ff7f3eb70d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e257d2b3-6a55-4559-804d-c028490ecbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read HDFS Weather Data\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://namenode:9000\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fbf60f5-a958-4906-a9ae-157b8e484d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(location):\n",
    "    df = spark.read.option(\"multiLine\", True) \\\n",
    "        .option(\"header\", True) \\\n",
    "        .option(\"inferSchema\", False) \\\n",
    "        .option(\"encoding\", \"utf-8\") \\\n",
    "        .csv(f\"hdfs://namenode:9000/tmp/weather_data/history/{location}.csv\")\n",
    "\n",
    "    df = df.toPandas()\n",
    "    \n",
    "    # Xóa các số đo, chỉ lấy giá trị\n",
    "    df['Temp'] = df['Temp'].str.replace('°c', '').str.strip()\n",
    "    df['Rain'] = df['Rain'].str.replace('\\nmm', '').str.strip()\n",
    "    df['Cloud'] = df['Cloud'].str.replace('%', '').str.strip()\n",
    "    df['Pressure'] = df['Pressure'].str.replace('mb', '').str.strip()\n",
    "    df['Wind'] = df['Wind'].str.replace('km/h', '').str.strip()\n",
    "    df['Gust'] = df['Gust'].str.replace('km/h', '').str.strip()\n",
    "\n",
    "    df = df.astype({\n",
    "        'Date': 'datetime64[ns]',\n",
    "        'Temp': 'float64',\n",
    "        'Rain': 'float64',\n",
    "        'Cloud': 'float64',\n",
    "        'Pressure': 'float64',\n",
    "        'Wind': 'float64',\n",
    "        'Gust': 'float64'\n",
    "    })\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        'Temp': 'Temp(°c)',\n",
    "        'Rain': 'Rain(nmm)',\n",
    "        'Cloud': 'Cloud(%)',\n",
    "        'Pressure': 'Pressure(mb)',\n",
    "        'Wind': 'Wind(km/h)',\n",
    "        'Gust': 'Gust(km/h)'\n",
    "    })\n",
    "\n",
    "    #Nhóm dữ liệu\n",
    "    weather_type1 = ['Sunny', 'Clear', 'Partly cloudy']\n",
    "    weather_type2 = ['Overcast', 'Cloudy', 'Patchy rain possible', 'Light drizzle', 'Light rain shower', 'Patchy light rain with thunder']\n",
    "    weather_type3 = ['Heavy rain at times', 'Moderate or heavy rain shower', 'Moderate rain at times', 'Moderate rain']\n",
    "\n",
    "    # Áp dụng số hóa cho cột 'Weather'\n",
    "    conditions = [\n",
    "        df['Weather'].isin(weather_type1),\n",
    "        df['Weather'].isin(weather_type2),\n",
    "        df['Weather'].isin(weather_type3)\n",
    "    ]\n",
    "    choices = [0, 1, 2]\n",
    "\n",
    "    df['Weather'] = np.select(conditions, choices, default=0)\n",
    "\n",
    "    #Lấy thông tin 6 mốc gần nhất để thêm dữ kiện\n",
    "    lag_steps = 6\n",
    "    for lag in range(1, lag_steps + 1):\n",
    "        df[f'Temp_t-{lag}'] = df['Temp(°c)'].shift(lag)\n",
    "        df[f'Rain_t-{lag}'] = df['Rain(nmm)'].shift(lag)\n",
    "        df[f'Cloud_t-{lag}'] = df['Cloud(%)'].shift(lag)\n",
    "        df[f'Pressure_t-{lag}'] = df['Pressure(mb)'].shift(lag)\n",
    "        df[f'Wind_t-{lag}'] = df['Wind(km/h)'].shift(lag)\n",
    "        df[f'Gust_t-{lag}'] = df['Gust(km/h)'].shift(lag)\n",
    "\n",
    "    df.drop(columns=['Date', 'Time'], inplace=True)\n",
    "\n",
    "    # Bỏ qua các hàng có giá trị NaN\n",
    "    X = df.drop(columns=['Weather'])\n",
    "    Y = df['Weather']\n",
    "    X = X[lag_steps:-1].reset_index(drop=True)\n",
    "    Y = Y[lag_steps + 1:].reset_index(drop=True)\n",
    "    X['Weather'] = Y\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b592d423-bd42-4668-9973-a68d4621e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_randomforest_model(provinces):\n",
    "    df_pd = pd.DataFrame()\n",
    "    for location in provinces:\n",
    "        df_cur = data_preprocess(location)\n",
    "        df_pd = pd.concat([df_pd, df_cur], ignore_index= True)\n",
    "    \n",
    "    # Có df pandas, convert sang spark:\n",
    "    df = spark.createDataFrame(df_pd)\n",
    "\n",
    "    #Chuyển dữ liệu về kiểu vector + standardize\n",
    "    feature_cols = df_pd.columns.tolist()  # Tất cả các cột trừ cột đầu tiên và cột cuối cùng\n",
    "    assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_assembled\")\n",
    "    scaler = StandardScaler(inputCol=\"features_assembled\", outputCol=\"features\")\n",
    "\n",
    "    #RandomForest\n",
    "    rf = RandomForestClassifier(labelCol=\"Weather\", featuresCol=\"features\")\n",
    "\n",
    "    #Pipeline\n",
    "    pipeline = Pipeline(stages=[assembler, scaler, rf])\n",
    "\n",
    "    #Grid Search\n",
    "    paramGrid = (ParamGridBuilder()\n",
    "        .addGrid(rf.numTrees, [50])\n",
    "        .addGrid(rf.maxDepth, [5])\n",
    "        .addGrid(rf.minInstancesPerNode, [2])\n",
    "        .build())\n",
    "\n",
    "    #Evaluation & CV\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"Weather\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "    cv = CrossValidator(estimator=pipeline,\n",
    "                        estimatorParamMaps=paramGrid,\n",
    "                        evaluator=evaluator,\n",
    "                        numFolds=5)\n",
    "\n",
    "    # 8. Chia train/test\n",
    "    train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "    # 9. Fit\n",
    "    cv_model = cv.fit(train_data)\n",
    "\n",
    "    # 10. Dự đoán và đánh giá\n",
    "    predictions = cv_model.transform(test_data)\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(f\"Accuracy = {accuracy}\")\n",
    "\n",
    "    #cv_model.save(f\"./Model/{name_file}_model\")\n",
    "\n",
    "    return cv_model, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30628db6-aad1-43b1-aae8-fb449d807f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "northern_provinces = [\n",
    "    'bac-can', 'bac-giang', 'bac-ninh', \n",
    "    'dien-bien', 'ha-giang', 'ha-noi', 'hai-duong', \n",
    "    'hai-phong', 'hoa-binh', 'hong-gai', \n",
    "    'lang-son', 'lao-cai', 'nam-dinh', 'ninh-binh', \n",
    "    'phu-ly', 'son-la', 'son-tay', 'thai-binh', \n",
    "    'thai-nguyen', 'tuyen-quang', 'uong-bi', 'viet-tri', \n",
    "    'vinh-yen'\n",
    "]\n",
    "\n",
    "central_provinces = [\n",
    "    'da-lat', 'dong-hoi', 'ha-tinh', 'hoi-an', \n",
    "    'hue', 'kon-tum', 'nha-trang', 'phan-rang', \n",
    "    'phan-thiet', 'play-cu', 'quang-ngai', 'qui-nhon', \n",
    "    'tam-ky', 'thanh-hoa', 'tuy-hoa', 'vinh', \n",
    "    'buon-me-thuot', 'cam-ranh'\n",
    "]\n",
    "\n",
    "southern_provinces = [\n",
    "    'bac-lieu', 'ben-tre', 'bien-hoa', 'ca-mau', \n",
    "    'chau-doc', 'dong-xoai', 'ho-chi-minh-city', \n",
    "    'long-xuyen', 'my-tho', 'rach-gia', 'soc-trang', \n",
    "    'tan-an', 'tay-ninh', 'tra-vinh', 'vinh-long', \n",
    "    'vung-tau'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae36ec23-43d7-4c41-ba0b-8a4866a861af",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_provinces = ['vinh','dong-hoi']\n",
    "\n",
    "rfmodel, accuracy = build_randomforest_model(list_provinces)\n",
    "print(f\"Model for vinh has been built and evaluated with accuracy :{accuracy}\")\n",
    "# rf_model.save(\"hdfs://namenode:9000/tmp/models/rf_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a499cbe2-749f-442f-8cbd-a8c7bacdc49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.save(\"hdfs://namenode:9000/tmp/models/rf_model\")\n",
    "# lưu model\n",
    "#model_path = \"path\"\n",
    "#lr_model.write().overwrite().save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d940e6eb-f081-4100-b8ec-3e272b488aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load lại model\n",
    "#from pyspark.ml.tuning import CrossValidatorModel\n",
    "#loaded_model = CrossValidatorModel.load(\"path\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
