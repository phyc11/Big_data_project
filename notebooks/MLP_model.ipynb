{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed35258c-2dae-4f9f-b809-9ee25c41b3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed31502-e8c7-416f-9d22-e194c2c0420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read HDFS Weather Data\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://namenode:9000\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf80e9-331c-4196-a27e-82473fe63693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(location):\n",
    "    df = spark.read.option(\"multiLine\", True) \\\n",
    "        .option(\"header\", True) \\\n",
    "        .option(\"inferSchema\", False) \\\n",
    "        .option(\"encoding\", \"utf-8\") \\\n",
    "        .csv(f\"hdfs://namenode:9000/tmp/weather_data/history/{location}.csv\")\n",
    "\n",
    "    df = df.toPandas()\n",
    "    \n",
    "    # Xóa các số đo, chỉ lấy giá trị\n",
    "    df['Temp'] = df['Temp'].str.replace('°c', '').str.strip()\n",
    "    df['Rain'] = df['Rain'].str.replace('\\nmm', '').str.strip()\n",
    "    df['Cloud'] = df['Cloud'].str.replace('%', '').str.strip()\n",
    "    df['Pressure'] = df['Pressure'].str.replace('mb', '').str.strip()\n",
    "    df['Wind'] = df['Wind'].str.replace('km/h', '').str.strip()\n",
    "    df['Gust'] = df['Gust'].str.replace('km/h', '').str.strip()\n",
    "\n",
    "    df = df.astype({\n",
    "        'Date': 'datetime64[ns]',\n",
    "        'Temp': 'float64',\n",
    "        'Rain': 'float64',\n",
    "        'Cloud': 'float64',\n",
    "        'Pressure': 'float64',\n",
    "        'Wind': 'float64',\n",
    "        'Gust': 'float64'\n",
    "    })\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        'Temp': 'Temp(°c)',\n",
    "        'Rain': 'Rain(nmm)',\n",
    "        'Cloud': 'Cloud(%)',\n",
    "        'Pressure': 'Pressure(mb)',\n",
    "        'Wind': 'Wind(km/h)',\n",
    "        'Gust': 'Gust(km/h)'\n",
    "    })\n",
    "\n",
    "    #Nhóm dữ liệu\n",
    "    weather_type1 = ['Sunny', 'Clear', 'Partly cloudy']\n",
    "    weather_type2 = ['Overcast', 'Cloudy', 'Patchy rain possible', 'Light drizzle', 'Light rain shower', 'Patchy light rain with thunder']\n",
    "    weather_type3 = ['Heavy rain at times', 'Moderate or heavy rain shower', 'Moderate rain at times', 'Moderate rain']\n",
    "\n",
    "    # Áp dụng số hóa cho cột 'Weather'\n",
    "    conditions = [\n",
    "        df['Weather'].isin(weather_type1),\n",
    "        df['Weather'].isin(weather_type2),\n",
    "        df['Weather'].isin(weather_type3)\n",
    "    ]\n",
    "    choices = [0, 1, 2]\n",
    "\n",
    "    df['Weather'] = np.select(conditions, choices, default=0)\n",
    "\n",
    "    #Lấy thông tin 6 mốc gần nhất để thêm dữ kiện\n",
    "    lag_steps = 6\n",
    "    for lag in range(1, lag_steps + 1):\n",
    "        df[f'Temp_t-{lag}'] = df['Temp(°c)'].shift(lag)\n",
    "        df[f'Rain_t-{lag}'] = df['Rain(nmm)'].shift(lag)\n",
    "        df[f'Cloud_t-{lag}'] = df['Cloud(%)'].shift(lag)\n",
    "        df[f'Pressure_t-{lag}'] = df['Pressure(mb)'].shift(lag)\n",
    "        df[f'Wind_t-{lag}'] = df['Wind(km/h)'].shift(lag)\n",
    "        df[f'Gust_t-{lag}'] = df['Gust(km/h)'].shift(lag)\n",
    "\n",
    "    df.drop(columns=['Date', 'Time'], inplace=True)\n",
    "\n",
    "    # Bỏ qua các hàng có giá trị NaN\n",
    "    X = df.drop(columns=['Weather'])\n",
    "    Y = df['Weather']\n",
    "    X = X[lag_steps:-1].reset_index(drop=True)\n",
    "    Y = Y[lag_steps + 1:].reset_index(drop=True)\n",
    "    X['Weather'] = Y\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b75226-dfe9-45b1-867d-380205196dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xây dựng và huấn luyện mô hình MLP\n",
    "def build_mlp_model(provinces):\n",
    "    df_pd = pd.DataFrame()\n",
    "    for location in provinces:\n",
    "        df_cur = data_preprocess(location)\n",
    "        df_pd = pd.concat([df_pd, df_cur], ignore_index= True)\n",
    "    \n",
    "    # Chuyển Pandas -> Spark DataFrame\n",
    "    df_spark = spark.createDataFrame(df_pd)\n",
    "\n",
    "    feature_cols = [c for c in df_pd.columns if c != 'Weather']\n",
    "    assembler = VectorAssembler(inputCols=feature_cols, outputCol='features_assembled')\n",
    "    scaler = StandardScaler(inputCol='features_assembled', outputCol='features')\n",
    "\n",
    "    # Định nghĩa cấu trúc lớp: input + 2 hidden + output\n",
    "    input_dim = len(feature_cols)\n",
    "    output_dim = df_pd['Weather'].nunique()  # 4 nếu có label 0\n",
    "    layers = [input_dim, 100, 50, output_dim]\n",
    "\n",
    "    mlp = MultilayerPerceptronClassifier(\n",
    "        labelCol='Weather',\n",
    "        featuresCol='features',\n",
    "        maxIter= 100,\n",
    "        layers=layers,\n",
    "        blockSize=128,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(stages=[assembler, scaler, mlp])\n",
    "\n",
    "    # Grid search tham số\n",
    "    paramGrid = (ParamGridBuilder()\n",
    "        .addGrid(mlp.maxIter, [100])\n",
    "        .addGrid(mlp.stepSize, [0.01])\n",
    "        .build())\n",
    "\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol='Weather',\n",
    "        predictionCol='prediction',\n",
    "        metricName='accuracy'\n",
    "    )\n",
    "\n",
    "    cv = CrossValidator(\n",
    "        estimator=pipeline,\n",
    "        estimatorParamMaps=paramGrid,\n",
    "        evaluator=evaluator,\n",
    "        numFolds=3\n",
    "    )\n",
    "\n",
    "    # Chia train/test 80/20\n",
    "    train_df, test_df = df_spark.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "    cv_model = cv.fit(train_df)\n",
    "    preds = cv_model.transform(test_df)\n",
    "    acc = evaluator.evaluate(preds)\n",
    "    print(f\"MLP Classifier Accuracy = {acc}\")\n",
    "\n",
    "    return cv_model, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cab53d-71ac-4f02-a4ac-58f82ea73747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier Accuracy = 0.7668228036101908\n",
      "Finished MLP training. Accuracy: 0.7668228036101908\n"
     ]
    }
   ],
   "source": [
    "northern_provinces = [\n",
    "    'bac-can', 'bac-giang', 'bac-ninh', \n",
    "    'dien-bien', 'ha-giang', 'ha-noi', 'hai-duong', \n",
    "    'hai-phong', 'hoa-binh', 'hong-gai', \n",
    "    'lang-son', 'lao-cai', 'nam-dinh', 'ninh-binh', \n",
    "    'phu-ly', 'son-la', 'son-tay', 'thai-binh', \n",
    "    'thai-nguyen', 'tuyen-quang', 'uong-bi', 'viet-tri', \n",
    "    'vinh-yen'\n",
    "]\n",
    "\n",
    "central_provinces = [\n",
    "    'da-lat', 'dong-hoi', 'ha-tinh', 'hoi-an', \n",
    "    'hue', 'kon-tum', 'nha-trang', 'phan-rang', \n",
    "    'phan-thiet', 'play-cu', 'quang-ngai', 'qui-nhon', \n",
    "    'tam-ky', 'thanh-hoa', 'tuy-hoa', 'vinh', \n",
    "    'buon-me-thuot', 'cam-ranh'\n",
    "]\n",
    "\n",
    "southern_provinces = [\n",
    "    'bac-lieu', 'ben-tre', 'bien-hoa', 'ca-mau', \n",
    "    'chau-doc', 'dong-xoai', 'ho-chi-minh-city', \n",
    "    'long-xuyen', 'my-tho', 'rach-gia', 'soc-trang', \n",
    "    'tan-an', 'tay-ninh', 'tra-vinh', 'vinh-long', \n",
    "    'vung-tau'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8952eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_provinces = ['vinh','dong-hoi']\n",
    "\n",
    "mlp_model, mlp_acc = build_mlp_model(list_provinces)\n",
    "print(\"Finished MLP training. Accuracy:\", mlp_acc)\n",
    "# mlp_model.save(\"hdfs://namenode:9000/tmp/models/mlp_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd172c51-3a62-4a3e-9c8e-e472a87de2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lưu model\n",
    "#model_path = \"path\"\n",
    "#lr_model.write().overwrite().save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe48bd-d7c4-4410-8523-5073cfdf9dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load lại model\n",
    "#from pyspark.ml.tuning import CrossValidatorModel\n",
    "#loaded_model = CrossValidatorModel.load(\"path\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
